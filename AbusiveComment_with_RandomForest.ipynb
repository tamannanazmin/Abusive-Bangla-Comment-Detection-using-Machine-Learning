{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AbusiveComment_with_NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01eZeazO71dd",
        "outputId": "9bda319c-1778-4d47-cff6-89287e115733"
      },
      "source": [
        "pip install bnlp_toolkit"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bnlp_toolkit\n",
            "  Downloading bnlp_toolkit-3.1.1-py3-none-any.whl (16 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 30.7 MB/s \n",
            "\u001b[?25hCollecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.4.1)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (0.8.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (3.2.5)\n",
            "Collecting gensim==4.0.1\n",
            "  Downloading gensim-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 94 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1->bnlp_toolkit) (5.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->bnlp_toolkit) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.8.9)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (4.62.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, sentencepiece, gensim, bnlp-toolkit\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed bnlp-toolkit-3.1.1 gensim-4.0.1 python-crfsuite-0.9.7 sentencepiece-0.1.96 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_TjVPPT86au",
        "outputId": "0b8127b6-cda0-4f0e-bb9b-9bbe11b8785d"
      },
      "source": [
        "pip install bnltk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bnltk\n",
            "  Downloading bnltk-0.7.6-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from bnltk) (2.6.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from bnltk) (2.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bnltk) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bnltk) (1.19.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from bnltk) (0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (3.0.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->bnltk) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->bnltk) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->bnltk) (1.4.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.39.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (2.6.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.7.4.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.1.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.12.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.2.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->bnltk) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->bnltk) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->bnltk) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->bnltk) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->bnltk) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->bnltk) (1.34.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->bnltk) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->bnltk) (0.4.5)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->bnltk) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->bnltk) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->bnltk) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->bnltk) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->bnltk) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->bnltk) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->bnltk) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow->bnltk) (3.5.0)\n",
            "Installing collected packages: bnltk\n",
            "Successfully installed bnltk-0.7.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC6Rjth_78Kd",
        "outputId": "3f5d7633-4afb-4fe0-c2f4-3d724ec8ad4e"
      },
      "source": [
        "pip install -U bnlp_toolkit"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bnlp_toolkit in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (0.8.2)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (0.3.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (0.1.96)\n",
            "Requirement already satisfied: gensim==4.0.1 in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (4.0.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1->bnlp_toolkit) (5.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->bnlp_toolkit) (1.15.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (4.62.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.8.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c5SIsz58E9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33cb1b3f-fbee-4a65-a666-042641d0e274"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from bnlp.corpus import stopwords\n",
        "from bnlp.corpus.util import remove_stopwords\n",
        "\n",
        "from bnltk.stemmer import BanglaStemmer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punkt not found. downloading...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTvSGM_N6lfk"
      },
      "source": [
        "from google.colab import drive\n",
        "dataset=pd.read_csv('/content/abusiveCommentInSocialMedia.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3QcFGkU4t3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130672f5-35fe-4874-99db-16f03b31a39f"
      },
      "source": [
        "#cleaning the texts\n",
        "import re\n",
        "corpus=[]\n",
        "for i in range(0,150):\n",
        "    review = re.sub('[‘’“”…,।.?!\"]', ' ', dataset['text'][i])\n",
        "    review = re.sub('\\n', '', review)\n",
        "    bn_stemmer = BanglaStemmer()\n",
        "    review=bn_stemmer.stem(review)\n",
        "    review = remove_stopwords(review, stopwords)\n",
        "    review=' '.join(review)\n",
        "    corpus.append(review)\n",
        "corpus\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['পরিমনি চামড়ার দোকান',\n",
              " 'সত্যি পরিমনি হিজলা কোনটা',\n",
              " 'প্রেমে অন্ধ ভালোবাসা',\n",
              " 'আল্লাহ্ লম্বা চুল দিয়েছিলো বলেই লজ্জা স্থানটুকু ঝাঁকতে পের',\n",
              " 'পিক দেখলে ছেলেরা তোমায় ধর্ষণ এটাও স্বাভাবিক',\n",
              " 'মেম্বার আপন',\n",
              " 'দেহ ব্যবসায়ী পরিমনি',\n",
              " 'দারুন পরি মনি',\n",
              " 'নিচের অবস্থা ত বেহাল দশা ইলিয়াস ভাই কৈই',\n",
              " 'ওহে সুন্দর বন্ধু মন লাগে রুপ লাগে',\n",
              " 'সুন্দর',\n",
              " 'পারলে ন্যাংটা হয়ে থাক',\n",
              " 'তুই একটা ভেসা মাগি',\n",
              " 'ইয়া আল্লাহ অন্তরে দুঃখ কষ্টের পাথর জমে অন্তরকে ধৈর্য দিয়ে প্রশান্তি দা',\n",
              " 'বন্ড সিরিজ মুভি মানেই এক আবেদন কটিই দেখেছি সিরিজটা দেখার দের বছর অপেক্ষা করছি একশন এডভেঞ্চার সাসপেন্স রোমান্স চেয়ে আসল কথা ফ্লিমের প্রতিটি চরিত্র সুন্দর ফুটিয়ে তোলা সত্যিই চমৎকার',\n",
              " 'অপেক্ষায় আছি',\n",
              " 'পেইজে বিখ্যাত কবি - সাহিত্যিকের পঙক্তি নিয়মিত পোস্ট হ',\n",
              " 'আফগানিস্তানের সাথে বাংলাদেশের বন্ধুত্ব করাবেন',\n",
              " 'তোরে ভালো করতাম তুই নমোকে লাইভে আসছিস নির্লজ্জ কোথাকার দুনিয়া মরে দেখ তোরে কবরে সৃজিতকে দেবে তোর সাথে ফাজিল এক',\n",
              " 'আলো বাজে মহিলাকে প্রচারণা রাস্তার মহিলার সম্মান মহিলার',\n",
              " 'চেহারায়তো মোটামুটি একটা গাজাখোরী চাপ পড়ছে বোঝা বুইড়ার সাথে সুখে চেহারায় বিষন্নতা',\n",
              " 'প্রিয় সাংবাদিক ভাই আপনাদের বাল ছাল টাইমলাইনে বিরক্তি লাগ',\n",
              " 'জয় পদ্মা সেতু',\n",
              " 'বিসিবির পক্ষ শোক প্রকাশ কর',\n",
              " 'এইগুলি তুচ্ছ ঘটনা',\n",
              " '২০২০ সালের মার্চ বাসায় বন্দি হয়ে আছি কোথাও হয়না',\n",
              " 'স্কুল কলেজ কাহারো মাথা বেথা নে',\n",
              " 'হে আল্লাহ বাচ্চারা ফুলের মত দিয়ে পরীক্ষা নিও রক্ষা কর',\n",
              " 'হে আল্লাহ বাচ্চাগুলোকে সুস্থতা হায়াত দান করুন দোয়া যেনো সুস্থ জীবনে আসে',\n",
              " 'গ্রামীণফোন রবি এয়ারটেল বাংলালিংক আকর্ষণীয় অফার সবচেয়ে কম মূল্যে পেতে গ্রুপের সাথেই থাকুন',\n",
              " 'সেক্সী পিক ভাল লাগ',\n",
              " 'আপু কাপড়ের অভাব',\n",
              " 'মাগি নষ্টামি করব',\n",
              " 'একটাা নোংরা মা',\n",
              " 'মালটা তিন রিমান্ডের কিভাবে টসটসে সেটার তদন্ত',\n",
              " 'আচ্ছা সাংবাদিক গুলো মেয়াদ উত্তীর্ণ গাজা খায়ছে সালা দেশের বারটা বাজতাছে এগুলা ডানা কাটা পরিরে মরে',\n",
              " 'মামনি ডিম থেরাপি চলছে',\n",
              " 'এইসব নেশা গ্রস্থ প্রষ্টিটিউট চারটা পাগল হয়ে গেলেই মরলেই আসে যায়',\n",
              " 'হায়েরে বাংলাদেশ সাংবাদিক এক লুইচ্চা মহিলারা সংবাদ ছুটা ছূটি কর',\n",
              " 'পরিমনি জেলখানায় মাল খাইতে একটু অসুস্ত হয়ে পরতেছে উকিলের একটু মালের ব্যবস্থা দে',\n",
              " 'তামিম ইকবালের সাক্ষাৎকারের কোহলির খারাপ মনোভাব দূর হয়ে',\n",
              " 'আলহামদুলিল্লাহ স্বপ্নের পদ্মা সেতু',\n",
              " 'বিসিবির পক্ষ শুভেচ্ছা অভিনন্দন',\n",
              " 'ভালো লাগছে বুঝাতে পারবো আলহামদুলিল্লাহ',\n",
              " 'পরিমনি বাল ছ',\n",
              " 'নাম পরিমনি নাম সোনা মনি খানকি সোনা হেডা সোনার বিতরে মা',\n",
              " 'কুত্তা লুচ্চা তুই খারাপ মুসলিম পরিবারের মেয়ে হয়ে খারাপ খারাপ ছবি আপ্লোড দেছ তোগো কারণেই যুব সমাজ নষ্ট হয়ে',\n",
              " 'একটা বেয়াদপ মেয়ে',\n",
              " 'আল্লাহ পাকের রহমত বঞ্চিত দেখুন অবস্থা আল্লাহ মুসলমানদের হেফাজত করুন আমিন',\n",
              " 'মানুষ মানুষের অবশ্যই সহায়তা',\n",
              " 'রোহিঙ্গা ইস্যুতে জাতিসংঘ চুপ কেনো',\n",
              " 'মানবিক সাহায্য রোহিঙ্গাদের পাঠানোর জোর দাবি জানাচ্ছি',\n",
              " 'প্রিয় সাংবাদিক বোন থাকলে বাল ছিড়েন আাগাছা পরিস্কার',\n",
              " 'থাকলে পুটকির ভিতর আঙুল দিয়ে বাথরুম ক্লিয়ার',\n",
              " 'কদম মত পেলে বাসে ফেরি কনডম বিক্রি করুন মত ফাউল সাংবাদিকের জন্ম রোধ',\n",
              " 'মিথিলার মত চামড়া ব্যবসায়ি দেখলে মনটা চায় মুখে পায়খানা',\n",
              " 'আফগানিস্তানে ক্ষমতায় আসলো গেলো সেসব চিন্তা দেশ চিন্তা উচিৎ',\n",
              " 'নারীদের নিরাপত্তা সবাই চিন্তিত',\n",
              " 'কোহলির এটিটিউড ভালো লাগে সেঞ্চুরি তেও সেলিব্রিট সবাইকে উৎসাহ দেওয়ার বিপক্ষ প্যানিক হওয়ার',\n",
              " 'আসেন দেশে দাওয়াত রইল',\n",
              " 'ভোটচোর হাসিনার সাথে সাক্ষাৎ',\n",
              " 'উনাকে সবসময় ফার্স্ট লেডি হ',\n",
              " 'মিথিলার চেহারাটা একটা ইয়াবা খোর মতন',\n",
              " 'সাংবাদিক গুলা ইদানিং চামড়ার পিছে ছুটছে কেনো',\n",
              " 'আলো বালেরেই কিজন্য আনে বালের বেকার সাংবাদিক',\n",
              " 'তোমাকে বোকা কীভাবে বানায় অলরেডি একটা গাধা',\n",
              " 'স্বাগতম দক্ষিণ এশিয়ায় আসবেন দক্ষিণ এশিয়ার উন্নয়ন যাবেন আশাবাদী',\n",
              " 'বাল ছেড়া গ',\n",
              " 'চীনের ভ্যাকসিন সফল',\n",
              " 'সিলেটের গর্ব',\n",
              " 'এভাবে বলবেন বলার মত অবস্থা নি',\n",
              " 'চালিয়ে এক্ষেত্রে সমর্থন',\n",
              " 'মনের কথায় বলছেন মাননীয় মন্ত্রীমহোদয়',\n",
              " 'এইবারে লকডাউন অনেকটা সারাজীবন বারোভাতারিগিরি বিয়ে বেলুন',\n",
              " 'দালালি ছাড়',\n",
              " 'তোমারে বোকা বানাইছে তোমারে বিয়া বুঝি আলো খালি মিথিলা মিথিলা ভাই বুঝিনা এসব বালের নিউজ দেখাটা ভালো',\n",
              " 'সাংবাদিকদের মা মিথিলার মাল্টিপ্লাগ বালছাল নিউজ',\n",
              " 'ওরে বারোবাতারি শেষ মুহূর্তে আকাটার গেলি ওরে বাটপ',\n",
              " 'বাল ছেড়া গ',\n",
              " 'এইটা বালটা ছাড়া লোক পাই',\n",
              " 'আলো ভাতারি মিথিলা নিয়া পড়ে বুঝিনা',\n",
              " 'বোকাচোদা তোমারে বানাবে পরিমনিরে বানাবে',\n",
              " 'জন্মদিনের শুভেচ্ছা',\n",
              " 'শুভ জন্মদিন কিংবদন্তি অভিনয়ের বরপুত্র ভালোবাসি',\n",
              " 'আচ্ছা কবরের রাতটা কেমন কাটবে কখনো ভেবেছি',\n",
              " 'পরিকল্পনা',\n",
              " 'জরিপে ভূমধ্যসাগর পাড়ি দিয়ে অধিবাসন প্রত্যাশী বাংলাদেশীর হার বেশী',\n",
              " '২০ বছর দখল জনগণের অন্যায় অত্যাচার করেছিল বলেই হয়তো ভয় পাচ্ছে',\n",
              " 'মাঝে আলো বেইশ\\u200d্যার বিজ্ঞাপন দেয়',\n",
              " 'মাথায় চোদেনা আলো আনফলো মারতে',\n",
              " 'বারোভাতারী আন্টি চাই মত',\n",
              " 'লিংক আপাকে বালের আলোর চুলকানি',\n",
              " 'বালের অনুষ্ঠান মিথিলা দেয় আলোরে',\n",
              " 'নিয়মিত সুন্দর সুন্দর পোস্ট পেতে পেজটি ফলো পাশেই থাকুন',\n",
              " 'আসসালামু আলাইকুম বন্ধুরা পুরান ঢাকা নিবাসি গাছ প্রেমি মানুষের গ্রুপ গাছ বিনিময় প্রদর্শন ক্রয় - বিক্রয় গাছ সংক্রান্ত প্রশ্নের নিয়মিত প্লিজ এখনই জয়েন ধন্যবাদ',\n",
              " 'নিচের পেইজটি পড়ে আনন্দ ঘরে সহজেই ইংরেজি শিখতে পারবেন ৷',\n",
              " 'গোপনের পাপ মানুষকে ধ্বংস দেয় গোপনের ইবাদত মানুষকে শ্রেষ্ঠ মর্যাদা দান কর',\n",
              " 'ভালো হই',\n",
              " 'সালা কুমারী মেয়ে বিয়ে বুইরা সৃজিত এজন্য চমকে ওঠ',\n",
              " 'মেলায় হারিয়ে ব্যজন্মা এক আলো মিথিলা',\n",
              " 'মিথিলা বলো কার পারফরম্যান্স ভালো তাহসান সৃজিত',\n",
              " 'খারাপ মহিলা গুলোকে কেনো মিডিয়াতে আনা ফালতু মহিলা',\n",
              " 'মিডিয়াগুলো চামড়ার বাজার জাত করতেছে',\n",
              " 'সতর্ক হোন সংবাদ মাধ্যম আপনাকে শিখাবে মজলুম ঘৃণা কর জালিমকে ভালোবাসো',\n",
              " 'যায় বুঝ',\n",
              " 'দৈনন্দিন বহুল ব্যবহারিত প্রিপোজিশন সময়ই লাগে',\n",
              " 'কষ্টের বিষ',\n",
              " 'পেইজে বিখ্যাত মনীষীদের উক্তি নিয়মিত পোস্ট হ',\n",
              " 'একজন বাঙালিকে ইউরোপের শীর্ষ লীগে পারলে ভালো লাগবে শুভকামনা রইলো',\n",
              " 'একটা বাজে মেয়ে আপনারা রিয়েলিটি শো আপনাদের লজ্জা বেয়াদবের দল আলোকে ভালোই করতাম সর্বকালের নিকৃষ্ট নিউজপোটাল আলো',\n",
              " 'সেলিব্রেটি বালদের দেখলেই বিরক্ত লাগে চিনার উপায় ভিতরে খাট কাপিয়ে আসছে তিনারাই জান',\n",
              " 'চিন্তায় চামড়ার ব্যাবসায় ধস খাবে চিন্তায় ঘুমায়',\n",
              " 'দাদারা সবসময়ই বোকা বানিয়ে আসছেন বোকা বানাচ্ছেন ইয়ে মারছেন আরো কতকি',\n",
              " 'তুই তো বাড়া বা\\u200cরো ভাতারী',\n",
              " 'আলোকে আনফলো করলাম বালচাল নিউজ',\n",
              " 'কৃষক মানে প্রকৃতির সাথে সর্বক্ষণ যুদ্ধ বেঁচে',\n",
              " 'সরকারের পক্ষ সহায়তা',\n",
              " 'আসুন ছেলে মেয়ে উভয়ের জন্যই চায়না পন্যের সমাহ',\n",
              " 'বাল ফালাইন্যা ছেড়ি পাইছেনা টকশো মারাইবার',\n",
              " 'তোর যোনীতে ক্যান্সার হওয়ার সসম্ভাবনা পেনিস অগ্রভাগের চামড়া কর্তন পেনিসের অগ্রভাগে চামড়ার প্রচুর পরিমানে ময়লা জমা সহবাসের টাইমে স্ত্রী যোনীতে প্রবেশ যোনী ক্যান্সার সসম্ভাবনা সবচেয়ে',\n",
              " 'নষ্টকে লেখালেখি করোস তোদের ভালো মানুষ চোখে পড়ে',\n",
              " 'এলাকা জীবন মানেই যুদ্ধ',\n",
              " 'আজীবন দেখি দূর অবস্থা সরকার কোনদিনও সমস্যা বের পারবে',\n",
              " 'আহারে জীবন জলে ভাসা পদ্মা',\n",
              " 'আল্লাহ রহমত কর',\n",
              " 'তামিমা তাম্মির মতই নির্লজ্জের মত সুন্দর কথা',\n",
              " 'আলো চামড়াজাত পণ্যের সাথে চামড়া ব্যবসায়ী বারোভাতারীদের ভালো প্রচারনা চালাচ্ছে',\n",
              " 'মাগী এক',\n",
              " 'নিয়মিত সুন্দর সুন্দর পোস্ট পেতে পেজটি ফলো পাশেই থাকুন',\n",
              " 'ভালোবাসা অবিরাম শিশির মনির ভাই সাবেক দায়িত্বশীল',\n",
              " 'আলহামদুলিল্লাহ মানবতার কল্যাণে সকল কার্যক্রম সফল কাম্য',\n",
              " 'মনির ভাই লেখা প্রবন্ধ পড়েছি',\n",
              " 'আরো ছোট কাপড় শালী',\n",
              " 'মাতারি তর প্রতিদিন সপ্ন দোষ তুই যেই সেকচি কাপড় পোষ্ট করস একদিনও গুমাতে পারিনা',\n",
              " 'পরিমনি কর',\n",
              " 'একটু খুললে মজা পাইতাম',\n",
              " 'বাংলার সানি লিওন বুকিংন খালি আ',\n",
              " 'কিরে মাগি তকে নেংটা',\n",
              " 'আল্লাহ মেয়েকে হেদায়েত দান করুন মৃত্যু কখন আসে টেরো পাবেনা আফসোস',\n",
              " 'ফালতু মেয়ে এক',\n",
              " 'নাম পরিমনি নাম মাগিমনি',\n",
              " 'তোমাকে সুন্দর লাগ',\n",
              " 'আলহামদুলিল্লাহ মানবতার কল্যাণে সকল কার্যক্রম সফল কাম্য',\n",
              " 'জনৈক বাংলাদেশী ভদ্রলোক একজন জাপানিজ মহিলাকে বিয়ে করেছিলো',\n",
              " 'ধন্যবাদ শিশির মনির ভা',\n",
              " 'সঠিক খবর',\n",
              " 'আপনাকে ধন্যবাদ সত্য কথা গুলো বলার',\n",
              " 'অধ্যক্ষ এইচ এম খায়রুল আনম চৌধুরী স্যারের মতন প্রাজ্ঞাভিজ্ঞ নেতাদের কথা মানলে দল দেশ দুইই উপকৃত',\n",
              " 'সাহস সত্য কথাটি বলার ধন্যবাদ',\n",
              " 'সমৃদ্ধ প্রতিবেদন']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBeoz7JDDFAY",
        "outputId": "cb098515-ae59-43a5-e35d-1bb96e33b10e"
      },
      "source": [
        "# TF-IDF process\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "cv = TfidfVectorizer()\n",
        "X= cv.fit_transform(corpus).toarray()\n",
        "y= dataset.iloc[:, 1].values\n",
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.27980115 ... 0.30286626 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "[1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0\n",
            " 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbX4W4_kDOdX",
        "outputId": "1512b8c1-8362-470f-9587-cc79fa39d3db"
      },
      "source": [
        "#Splitting the dataset into training set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "print(X)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.27980115 ... 0.30286626 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTpUGljIDVm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bcd574d-1d45-45c0-f6a7-a71be63c9a87"
      },
      "source": [
        "\n",
        "# Fitting Random Forest to the training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeGHGUdNK7-J"
      },
      "source": [
        "#predicting the Test set results\n",
        "y_pred=classifier.predict(X_test)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo1hKTOfK93Q",
        "outputId": "51ec0992-2b2f-443f-b85d-43771a27e68a"
      },
      "source": [
        "#Making the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 12]\n",
            " [ 3 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFJAOxtwK_yA",
        "outputId": "5bbc07f3-b995-49fa-918a-999ddc0c42c4"
      },
      "source": [
        "#finding accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy=accuracy_score(y_test,y_pred)\n",
        "print(accuracy)\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPfhURHrSnHV",
        "outputId": "e6b61d1e-741b-4980-f978-a7d70720d792"
      },
      "source": [
        "#finding Recall\n",
        "from sklearn.metrics import recall_score\n",
        "recall=recall_score(y_test,y_pred,average=\"binary\")\n",
        "print('Recall %.3f'%recall)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall 0.800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09CPw7LsTTZG",
        "outputId": "20fa818a-9699-4ba2-f0ee-59486316b7cf"
      },
      "source": [
        "#finding Precision\n",
        "from sklearn.metrics import precision_score\n",
        "precision=precision_score(y_test,y_pred,average=\"binary\")\n",
        "print('precision %.3f'%precision)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision 0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b670sBedTgFP",
        "outputId": "ad5e6ee5-c36b-4c16-90d0-e81ead6bcda8"
      },
      "source": [
        "#finding F1-score\n",
        "from sklearn.metrics import f1_score\n",
        "f1=f1_score(y_test,y_pred,average=\"binary\")\n",
        "print('f1_score %.3f'%f1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score 0.615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ue3DhNjR8Ym"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}